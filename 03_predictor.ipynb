{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a611fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8449d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from brokit.primitives.lm import LM, ModelType, ModelResponse, Usage, Message\n",
    "from typing import List, Optional\n",
    "\n",
    "class Llama(LM):\n",
    "    def __init__(self, model_name: str, base_url:str = \"http://localhost:11434\", temperature:float=0.0, top_p:float=1.0, seed:int=55, **kwargs):\n",
    "        super().__init__(model_name=model_name, model_type=ModelType.CHAT)\n",
    "        self.base_url = base_url\n",
    "        self.client = httpx.Client(timeout=60.0)  # Reusable client)\n",
    "        self.model_params = {\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"seed\": seed,\n",
    "            **kwargs\n",
    "        }\n",
    "\n",
    "    def request(self, prompt:Optional[str]=None, messages:Optional[List[Message]]=None, **kwargs) -> dict:\n",
    "        url = f\"{self.base_url}/api/chat\"\n",
    "        params = {**self.model_params, **kwargs}\n",
    "        if messages is not None:\n",
    "            _messages = [msg.to_dict() if isinstance(msg, Message) else msg for msg in messages]\n",
    "        else:\n",
    "            _messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = self.client.post(\n",
    "            url,\n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": _messages,\n",
    "                \"stream\": False,\n",
    "                \"options\": {**params},\n",
    "            }\n",
    "        )                \n",
    "        return response.json()\n",
    "\n",
    "    def parse_response(self, original_response: dict) -> ModelResponse:\n",
    "        message = original_response[\"message\"]\n",
    "        input_tokens = original_response.get(\"prompt_eval_count\", 0)\n",
    "        output_tokens = original_response.get(\"eval_count\", 0)\n",
    "        return ModelResponse(\n",
    "            model_name=self.model_name,\n",
    "            model_type=self.model_type,\n",
    "            response=message[\"content\"],\n",
    "            usage=Usage(input_tokens=input_tokens, output_tokens=output_tokens),\n",
    "            metadata=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d683f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokit.primitives.prompt import Prompt, InputField, OutputField\n",
    "\n",
    "class QA(Prompt):\n",
    "    \"\"\"Answer a question based on the provided context.\"\"\"\n",
    "    question:str = InputField(description=\"The question to be answered.\")\n",
    "    dice:int = OutputField(description=\"roll the dice, its outcome ranging from 1 to 6\")\n",
    "    logic:bool = OutputField(description=\"if the dice's outcome is greater than or equal to 5, logic=True, otherwise False\")\n",
    "    answer:str = OutputField(description=\"If logic=True, answer the question in sarcastic tone, else smooth-tone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea494be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokit.primitives.predictor import Predictor\n",
    "\n",
    "# lm = Llama(model_name=\"gemma3:12b\")\n",
    "lm = Llama(model_name=\"gemma3:12b\")\n",
    "predictor = Predictor(prompt=QA, lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ff47dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    dice=3,\n",
       "    logic=False,\n",
       "    answer=\"I've been quite well, thank you for asking! Just doing my usual AI things. How about yourself?\"\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = predictor(question=\"How ya been?\")\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c67ec29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " False,\n",
       " \"I've been quite well, thank you for asking! Just doing my usual AI things. How about yourself?\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.dice, prediction.logic, prediction.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5007ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(model_name='gemma3:12b', model_type=<ModelType.CHAT: 'chat'>, response=\"<||dice||>\\n3\\n\\n<||logic||>\\nFalse\\n\\n<||answer||>\\nI've been quite well, thank you for asking! Just doing my usual AI things. How about yourself?\\n\\n<||completed||>\", usage=Usage(input_tokens=259, output_tokens=52), response_ms=3081.1028000025544, cached=False, metadata=None, request=[Message(role='system', content=\"Your input fields are:\\n1. question (<class 'str'>): The question to be answered.\\nYour output fields are:\\n1. dice (<class 'int'>): roll the dice, its outcome ranging from 1 to 6\\n2. logic (<class 'bool'>): if the dice's outcome is greater than or equal to 5, logic=True, otherwise False\\n3. answer (<class 'str'>): If logic=True, answer the question in sarcastic tone, else smooth-tone.\\n\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n<||question||>\\n{question}\\n\\n<||dice||>\\n{dice}\\n\\n<||logic||>\\n{logic}\\n\\n<||answer||>\\n{answer}\\n\\n<||completed||>\\nIn adhering to this structure, your objective is: \\nAnswer a question based on the provided context.\", images=None), Message(role='user', content='<||question||>\\nHow ya been?\\n\\nRespond with the corresponding output fields, starting with the field: `<||dice||>`, `<||logic||>`, `<||answer||>` and then ending with the marker for `<||completed||>`.', images=None)], parsed_response={'dice': 3, 'logic': False, 'answer': \"I've been quite well, thank you for asking! Just doing my usual AI things. How about yourself?\"})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cfa991a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<||dice||>\\n3\\n\\n<||logic||>\\nFalse\\n\\n<||answer||>\\nI've been quite well, thank you for asking! Just doing my usual AI things. How about yourself?\\n\\n<||completed||>\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history[-1].response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71ae7902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Message(role='system', content=\"Your input fields are:\\n1. question (<class 'str'>): The question to be answered.\\nYour output fields are:\\n1. dice (<class 'int'>): roll the dice, its outcome ranging from 1 to 6\\n2. logic (<class 'bool'>): if the dice's outcome is greater than or equal to 5, logic=True, otherwise False\\n3. answer (<class 'str'>): If logic=True, answer the question in sarcastic tone, else smooth-tone.\\n\\nAll interactions will be structured in the following way, with the appropriate values filled in.\\n\\n<||question||>\\n{question}\\n\\n<||dice||>\\n{dice}\\n\\n<||logic||>\\n{logic}\\n\\n<||answer||>\\n{answer}\\n\\n<||completed||>\\nIn adhering to this structure, your objective is: \\nAnswer a question based on the provided context.\", images=None),\n",
       " Message(role='user', content='<||question||>\\nHow ya been?\\n\\nRespond with the corresponding output fields, starting with the field: `<||dice||>`, `<||logic||>`, `<||answer||>` and then ending with the marker for `<||completed||>`.', images=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history[-1].request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ea3476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDescriptor(Prompt):\n",
    "    \"\"\"Describe images\"\"\"\n",
    "    description:str = OutputField(description=\"description of images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "084691d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDescriptor.input_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6ca17b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': FieldInfo(name='description', description='description of images', type=<class 'str'>, is_input=False)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDescriptor.output_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1223d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Describe images'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageDescriptor.instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f726cfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = Predictor(ImageDescriptor, lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9682630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokit.primitives.prompt import Image\n",
    "doraemon1 = Image(\"https://aithailand.co.th/wp-content/uploads/2024/09/Doraemon-th_1630640671-1024x635.jpg\")\n",
    "nobita1 = Image(\"https://m.media-amazon.com/images/M/MV5BM2E5MDIwNjktOWQwYS00ODg5LTlhN2MtNzU1OTc3MDA0NjNmXkEyXkFqcGc@._V1_FMjpg_UX1000_.jpg\")\n",
    "\n",
    "response = ip(images=[doraemon1, nobita1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3baeafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    description='The first image shows the character Doraemon, a blue robotic cat from a Japanese manga and anime series. He is depicted smiling and waving with one hand, wearing his signature bell around his neck. The word \"DORAEMON\" is written in large, bold letters below him. The background is a light blue color.\\n\\nThe second image shows a close-up of a boy wearing glasses and a yellow shirt. He is smiling widely, showing his teeth. The background appears to be a rooftop with greenery.'\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aad73a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system Your output fields are:\n",
      "1. description (<class 'str'>): description of images\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "<||description||>\n",
      "{description}\n",
      "\n",
      "<||completed||>\n",
      "In adhering to this structure, your objective is: \n",
      "Describe images\n",
      "==========\n",
      "user Respond with the corresponding output fields, starting with the field: `<||description||>` and then ending with the marker for `<||completed||>`.\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for h in lm.history[-1].request:\n",
    "    print(h.role, h.content)\n",
    "    print(\"=\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brokit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
