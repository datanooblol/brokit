{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e7ddb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f88ae8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from brokit.primitives.lm import LM, ModelType, ModelResponse, Usage, Message\n",
    "from typing import List, Optional\n",
    "\n",
    "class Llama(LM):\n",
    "    def __init__(self, model_name: str, base_url:str = \"http://localhost:11434\", temperature:float=0.0, top_p:float=1.0, seed:int=55, **kwargs):\n",
    "        super().__init__(model_name=model_name, model_type=ModelType.CHAT)\n",
    "        self.base_url = base_url\n",
    "        self.client = httpx.Client(timeout=60.0)  # Reusable client)\n",
    "        self.model_params = {\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"seed\": seed,\n",
    "            **kwargs\n",
    "        }\n",
    "\n",
    "    def request(self, prompt:Optional[str]=None, messages:Optional[List[Message]]=None, **kwargs) -> dict:\n",
    "        url = f\"{self.base_url}/api/chat\"\n",
    "        params = {**self.model_params, **kwargs}\n",
    "        if messages is not None:\n",
    "            _messages = [msg.to_dict() if isinstance(msg, Message) else msg for msg in messages]\n",
    "        else:\n",
    "            _messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        response = self.client.post(\n",
    "            url,\n",
    "            json={\n",
    "                \"model\": self.model_name,\n",
    "                \"messages\": _messages,\n",
    "                \"stream\": False,\n",
    "                \"options\": {**params},\n",
    "            }\n",
    "        )                \n",
    "        return response.json()\n",
    "\n",
    "    def parse_response(self, original_response: dict) -> ModelResponse:\n",
    "        message = original_response[\"message\"]\n",
    "        input_tokens = original_response.get(\"prompt_eval_count\", 0)\n",
    "        output_tokens = original_response.get(\"eval_count\", 0)\n",
    "        return ModelResponse(\n",
    "            model_name=self.model_name,\n",
    "            model_type=self.model_type,\n",
    "            response=message[\"content\"],\n",
    "            usage=Usage(input_tokens=input_tokens, output_tokens=output_tokens),\n",
    "            metadata=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0af7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokit.primitives.prompt import Prompt, InputField, OutputField\n",
    "from brokit.primitives.shot import Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fec51f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QA(Prompt):\n",
    "    \"\"\"Think and answer the question\"\"\"\n",
    "    question:str = InputField(description=\"The question\")\n",
    "    reason:str = OutputField(description=\"Think and share the reason why you answer like this\")\n",
    "    answer:str = OutputField(description=\"Your answer based on question and reason\")\n",
    "\n",
    "shots = [\n",
    "    Shot(QA, question=\"1+1\", answer=\"2\"),\n",
    "    Shot(QA, question=\"Where's the capital of Thailand\", answer=\"Bangkok\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d802aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'question': '1+1'}, {'reason': 'Intentionally left blank.', 'answer': '2'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "shots[idx].inputs, shots[idx].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef5db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokit.primitives.predictor import Predictor\n",
    "\n",
    "# lm = Llama(model_name=\"gemma3:12b\")\n",
    "lm = Llama(model_name=\"gemma3:12b\")\n",
    "predictor = Predictor(prompt=QA, lm=lm, shots=shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0da516d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reason='This is a simple addition problem. The number 1 added to the number 1 equals 2.',\n",
       "    answer='2'\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = predictor(question=\"1+1\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dca022c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM\n",
      "Your input fields are:\n",
      "1. question (<class 'str'>): The question\n",
      "Your output fields are:\n",
      "1. reason (<class 'str'>): Think and share the reason why you answer like this\n",
      "2. answer (<class 'str'>): Your answer based on question and reason\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "<||question||>\n",
      "{question}\n",
      "\n",
      "<||reason||>\n",
      "{reason}\n",
      "\n",
      "<||answer||>\n",
      "{answer}\n",
      "\n",
      "<||completed||>\n",
      "In adhering to this structure, your objective is: \n",
      "Think and answer the question\n",
      "====================\n",
      "USER\n",
      "<||question||>\n",
      "1+1\n",
      "====================\n",
      "ASSISTANT\n",
      "<||reason||>\n",
      "Intentionally left blank.\n",
      "\n",
      "<||answer||>\n",
      "2\n",
      "\n",
      "<||completed||>\n",
      "====================\n",
      "USER\n",
      "<||question||>\n",
      "Where's the capital of Thailand\n",
      "====================\n",
      "ASSISTANT\n",
      "<||reason||>\n",
      "Intentionally left blank.\n",
      "\n",
      "<||answer||>\n",
      "Bangkok\n",
      "\n",
      "<||completed||>\n",
      "====================\n",
      "USER\n",
      "<||question||>\n",
      "1+1\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field: `<||reason||>`, `<||answer||>` and then ending with the marker for `<||completed||>`.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for h in lm.history[-1].request:\n",
    "    print(h.role.upper())\n",
    "    print(h.content)\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06f83cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Usage(input_tokens=284, output_tokens=42)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.history[0].usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090c5fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = 0\n",
    "output_tokens = 0\n",
    "\n",
    "for h in lm.history:\n",
    "    input_tokens += h.usage.input_tokens\n",
    "    output_tokens += h.usage.output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21838d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens, output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5dafdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brokit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
